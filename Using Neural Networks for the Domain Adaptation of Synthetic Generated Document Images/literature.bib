@preamble{ "\newcommand{\noopsort}[1]{} "
	# "\newcommand{\printfirst}[2]{#1} "
	# "\newcommand{\singleletter}[1]{#1} "
	# "\newcommand{\switchargs}[2]{#2#1} " }



@article{goodfellow2017deep,
  title={Deep learning (adaptive computation and machine learning series)},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  journal={Cambridge Massachusetts},
  pages={321--359},
  year={2017}
}

@book{10.5555/3153997,
author = {Gron, Aurlien},
title = {Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},
year = {2017},
isbn = {1491962291},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Graphics in this book are printed in black and white. Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. By using concrete examples, minimal theory, and two production-ready Python frameworksscikit-learn and Tensor Flowauthor Aurlien Gron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. Youll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what youve learned, all you need is programming experience to get started. Explore the machine learning landscape, particularly neural nets Use scikit-learn to track an example machine-learning project end-to-end Explore several training models, including support vector machines, decision trees, random forests, and ensemble methods Use the Tensor Flow library to build and train neural nets Dive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learning Learn techniques for training and scaling deep neural nets Apply practical code examples without acquiring excessive machine learning theory or algorithm details}
}

@misc{oshea2015introduction,
      title={An Introduction to Convolutional Neural Networks}, 
      author={Keiron O'Shea and Ryan Nash},
      year={2015},
      eprint={1511.08458},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}


@book{langr2019gans,
  title={GANs in Action: Deep learning with Generative Adversarial Networks},
  author={Langr, J. and Bok, V.},
  isbn={9781617295560},
  lccn={2019286864},
  url={https://books.google.de/books?id=HojvugEACAAJ},
  year={2019},
  publisher={Manning Publications}
}


@misc{ruder2017overview,
      title={An overview of gradient descent optimization algorithms}, 
      author={Sebastian Ruder},
      year={2017},
      eprint={1609.04747},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{10.5555/3086952,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
title = {Deep Learning},
year = {2016},
isbn = {0262035618},
publisher = {The MIT Press},
abstract = {"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject." -- Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.}
}

@misc{kukacka2017regularization,
      title={Regularization for Deep Learning: A Taxonomy}, 
      author={Jan Kukačka and Vladimir Golkov and Daniel Cremers},
      year={2017},
      eprint={1710.10686},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{5288526,  author={Pan, Sinno Jialin and Yang, Qiang},  journal={IEEE Transactions on Knowledge and Data Engineering},   
title={A Survey on Transfer Learning},   year={2010},  volume={22},  number={10},  pages={1345-1359},  doi={10.1109/TKDE.2009.191}}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{mirza2014conditional,
      title={Conditional Generative Adversarial Nets}, 
      author={Mehdi Mirza and Simon Osindero},
      year={2014},
      eprint={1411.1784},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhuang2020comprehensive,
      title={A Comprehensive Survey on Transfer Learning}, 
      author={Fuzhen Zhuang and Zhiyuan Qi and Keyu Duan and Dongbo Xi and Yongchun Zhu and Hengshu Zhu and Hui Xiong and Qing He},
      year={2020},
      eprint={1911.02685},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{8580565,  author={Yue, Liu and Ganesan, Packyanathan and Sathish, B. S. and Manikandan, 
C. and Niranjan, A. and Elamaran, V. and Hussein, Ahmed Faeq},  journal={IEEE Access},   
title={The Importance of Dithering Technique Revisited With Biomedical Images—A Survey},   
year={2019},  volume={7},  number={},  pages={3627-3634},  doi={10.1109/ACCESS.2018.2888503}}

@misc{lipton2014thresholding,
      title={Thresholding Classifiers to Maximize F1 Score}, 
      author={Zachary Chase Lipton and Charles Elkan and Balakrishnan Narayanaswamy},
      year={2014},
      eprint={1402.1892},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{lin2015microsoft,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{8978087,  
	author={C. {Tensmeyer} and M. {Brodie} and D. {Saunders} and T. {Martinez}},  
	booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},   
	title={Generating Realistic Binarization Data with Generative Adversarial Networks},   
	year={2019},  
	volume={},  
	number={},  
	pages={172-177},  
	doi={10.1109/ICDAR.2019.00036}
}

@misc{nam2021reducing,
      title={Reducing Domain Gap by Reducing Style Bias}, 
      author={Hyeonseob Nam and HyunJae Lee and Jongchan Park and Wonjun Yoon and Donggeun Yoo},
      year={2021},
      eprint={1910.11645},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{mao2017squares,
      title={Least Squares Generative Adversarial Networks}, 
      author={Xudong Mao and Qing Li and Haoran Xie and Raymond Y. K. Lau and Zhen Wang and Stephen Paul Smolley},
      year={2017},
      eprint={1611.04076},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}




@INPROCEEDINGS{9023664,
  author={H. {Li} and J. {Li} and X. {Guan} and B. {Liang} and Y. {Lai} and X. {Luo}},
  booktitle={2019 15th International Conference on Computational Intelligence and Security (CIS)}, 
  title={Research on Overfitting of Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={78-81},
  doi={10.1109/CIS.2019.00025}}


@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@online{nain2021,
	title = {keras-team/keras-io},
	url = {https://github.com/keras-team/keras-io},
	abstract = {Keras documentation, hosted live at keras.io. Contribute to keras-team/keras-io development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2021-04-07},
	langid = {english},
}


@misc{tensorflow2015-whitepaper,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}


% This file was created with Citavi 6.4.0.35

@article{Zhao.2020,
 abstract = {Nowadays, with the development of electronic devices, more and more attention has been paid to camera-based text processing. Different from scene image, the recognition system of document image needs to sort out the recognition results and store them in the structured document for the subsequent data processing. However, in document images, the fusion of text lines largely depends on their semantic information rather than just the distance between the characters, which causes the problem of learning confusion in training. At the same time, for multi-directional printed characters in document images, it is necessary to use additional directional information to guide subsequent recognition tasks. In order to avoid learning confusion and get recognition-friendly detection results, we propose a character-level text detection framework, DetectGAN, based on the conditional generative adversarial networks (abbreviation cGAN used in the text). In the proposed framework, position regression and NMS process are removed, and the problem of text detection is directly transformed into an image-to-image generation problem. Experimental results show that our method has an excellent effect on text detection of camera-captured document images and outperforms the classical and state-of-the-art algorithms.},
 author = {Zhao, Jinyuan and Wang, Yanna and Xiao, Baihua and Shi, Cunzhao and Jia, Fuxi and Wang, Chunheng},
 year = {2020},
 title = {DetectGAN: GAN-based text detector for camera-captured document images},
 pages = {267--277},
 volume = {23},
 number = {4},
 issn = {1433-2825},
 journal = {International Journal on Document Analysis and Recognition (IJDAR)},
 doi = {10.1007/s10032-020-00358-w}
}

% This file was created with Citavi 6.4.0.35

@article{PavanKumar.2021,
 abstract = {Deep neural networks have attained great success in handling high dimensional data, especially images. However, generating naturalistic images containing ginormous subjects for different tasks like image classification, segmentation, object detection, reconstruction, etc., is continued to be a difficult task. Generative modelling has the potential to learn any kind of data distribution in an unsupervised manner. Variational autoencoder (VAE), autoregressive models, and generative adversarial network (GAN) are the popular generative modelling approaches that generate data distributions. Among these, GANs have gained much attention from the research community in recent years in terms of generating quality images and data augmentation. In this context, we collected research articles that employed GANs for solving various tasks from popular databases and summarized them based on their application. The main objective of this article is to present the nuts and bolts of GANs, state-of-the-art related work and its applications, evaluation metrics, challenges involved in training GANs, and benchmark datasets that would benefit naive and enthusiastic researchers who are interested in working on GANs.},
 author = {{Pavan Kumar}, M. R. and Jayagopal, Prabhu},
 year = {2021},
 title = {Generative adversarial networks: a survey on applications and challenges},
 pages = {1--24},
 volume = {10},
 number = {1},
 issn = {2192-662X},
 journal = {International Journal of Multimedia Information Retrieval},
 doi = {10.1007/s13735-020-00196-w}
}





@book{2020,
	doi = {10.1007/978-3-030-44289-7},
	url = {https://doi.org/10.1007%2F978-3-030-44289-7},
	year = 2020,
	publisher = {Springer International Publishing},
	editor = {Aboul-Ella Hassanien and Ahmad Taher Azar and Tarek Gaber and Diego Oliva and Fahmy M. Tolba},
	title = {Proceedings of the International Conference on Artificial Intelligence and Computer Vision ({AICV}2020)}
}

@misc{yi2018dualgan,
      title={DualGAN: Unsupervised Dual Learning for Image-to-Image Translation}, 
      author={Zili Yi and Hao Zhang and Ping Tan and Minglun Gong},
      year={2018},
      eprint={1704.02510},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@Inbook{Girimonte2007,
author="Girimonte, Daniela
and Izzo, Dario",
editor="Schuster, Alfons J.",
title="Artificial Intelligence for Space Applications",
bookTitle="Intelligent Computing Everywhere",
year="2007",
publisher="Springer London",
address="London",
pages="235--253",
abstract="The ambitious short-term and long-term goals set down by the various national space agencies call for radical advances in several of the main space engineering areas, the design of intelligent space agents certainly being one of them. In recent years, this has led to an increasing interest in artificial intelligence by the entire aerospace community. However, in the current state of the art, several open issues and showstoppers can be identified. In this chapter, we review applications of artificial intelligence in the field of space engineering and space technology and identify open research questions and challenges. In particular, the following topics are identified and discussed: distributed artificial intelligence, enhanced situation self-awareness, and decision support for spacecraft system design.",
isbn="978-1-84628-943-9",
doi="10.1007/978-1-84628-943-9_12",
url="https://doi.org/10.1007/978-1-84628-943-9_12"
}




@InProceedings{10.1007/978-3-642-82153-0_2,
author="Brady, Michael",
editor="Brady, Michael
and Gerhardt, Lester A.
and Davidson, Harold F.",
title="Artificial Intelligence and Robotics",
booktitle="Robotics and Artificial Intelligence",
year="1984",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="47--63",
abstract="Robotics is that field concerned with the connection of perception to action. Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how that knowledge should be represented; and how that knowledge should be used Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge.",
isbn="978-3-642-82153-0"
}



@article{Yurtsever_2020,
   title={A Survey of Autonomous Driving: Common Practices and Emerging Technologies},
   volume={8},
   ISSN={2169-3536},
   url={http://dx.doi.org/10.1109/ACCESS.2020.2983149},
   DOI={10.1109/access.2020.2983149},
   journal={IEEE Access},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
   year={2020},
   pages={58443–58469}
}


@article{Yu.2018,
 abstract = {Artificial intelligence (AI) is gradually changing medical practice. With recent progress in digitized data acquisition, machine learning and computing infrastructure, AI applications are expanding into areas that were previously thought to be only the province of human experts. In this Review Article, we outline recent breakthroughs in AI technologies and their biomedical applications, identify the challenges for further progress in medical AI systems, and summarize the economic, legal and social implications of AI in healthcare.},
 author = {Yu, Kun-Hsing and Beam, Andrew L. and Kohane, Isaac S.},
 year = {2018},
 title = {Artificial intelligence in healthcare},
 pages = {719--731},
 volume = {2},
 number = {10},
 issn = {2157-846X},
 journal = {Nature Biomedical Engineering},
 doi = {10.1038/s41551-018-0305-z}
}


@article{gopalan2015domain,
  title={Domain adaptation for visual recognition},
  author={Gopalan, Raghuraman and Li, Ruonan and Patel, Vishal M and Chellappa, Rama},
  journal={Foundations and Trends{\textregistered} in Computer Graphics and Vision},
  volume={8},
  number={4},
  pages={285--378},
  year={2015},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}

@InProceedings{10.1007/978-3-319-10602-1_48,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="740--755",
abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
isbn="978-3-319-10602-1"
}




@misc{huang2018multimodal,
      title={Multimodal Unsupervised Image-to-Image Translation}, 
      author={Xun Huang and Ming-Yu Liu and Serge Belongie and Jan Kautz},
      year={2018},
      eprint={1804.04732},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{8978011,  author={Q. A. {Bui} and D. {Mollard} and S. {Tabbone}},  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},   title={Automatic Synthetic Document Image Generation using Generative Adversarial Networks: Application in Mobile-Captured Document Analysis},   year={2019},  volume={},  number={},  pages={393-400},  doi={10.1109/ICDAR.2019.00070}}

@misc{isola2018imagetoimage,
      title={Image-to-Image Translation with Conditional Adversarial Networks}, 
      author={Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
      year={2018},
      eprint={1611.07004},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{hemmer2020deal,
      title={DEAL: Deep Evidential Active Learning for Image Classification}, 
      author={Patrick Hemmer and Niklas Kühl and Jakob Schöffer},
      year={2020},
      eprint={2007.11344},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



% This file was created with Citavi 6.4.0.35

@article{Shorten.2019,
 abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
 author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
 year = {2019},
 title = {A survey on Image Data Augmentation for Deep Learning},
 pages = {60},
 volume = {6},
 number = {1},
 issn = {2196-1115},
 journal = {Journal of Big Data},
 doi = {10.1186/s40537-019-0197-0}
}


@misc{redko2020survey,
      title={A survey on domain adaptation theory: learning bounds and theoretical guarantees}, 
      author={Ievgen Redko and Emilie Morvant and Amaury Habrard and Marc Sebban and Younès Bennani},
      year={2020},
      eprint={2004.11829},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@book{DavidFoster,
 author = {David Foster},
 title = {Generative Deep Learning},
 year={2019},
 publisher = {O'Reilly Media, Inc.},
 isbn = {9781492041948}
}

@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{zhu2020unpaired,
      title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}, 
      author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
      year={2020},
      eprint={1703.10593},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{park2020contrastive,
      title={Contrastive Learning for Unpaired Image-to-Image Translation}, 
      author={Taesung Park and Alexei A. Efros and Richard Zhang and Jun-Yan Zhu},
      year={2020},
      eprint={2007.15651},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{sharma2019learning,
      title={Learning to Clean: A GAN Perspective}, 
      author={Monika Sharma and Abhishek Verma and Lovekesh Vig},
      year={2019},
      eprint={1901.11382},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{arjovsky2017wasserstein,
      title={Wasserstein GAN}, 
      author={Martin Arjovsky and Soumith Chintala and Léon Bottou},
      year={2017},
      eprint={1701.07875},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@Inbook{Metta2012,
author="Metta, Giorgio
and Cangelosi, Angelo",
editor="Seel, Norbert M.",
title="Cognitive Robotics",
bookTitle="Encyclopedia of the Sciences of Learning",
year="2012",
publisher="Springer US",
address="Boston, MA",
pages="613--616",
isbn="978-1-4419-1428-6",
doi="10.1007/978-1-4419-1428-6_654",
url="https://doi.org/10.1007/978-1-4419-1428-6_654"
}




@misc{gulrajani2017improved,
      title={Improved Training of Wasserstein GANs}, 
      author={Ishaan Gulrajani and Faruk Ahmed and Martin Arjovsky and Vincent Dumoulin and Aaron Courville},
      year={2017},
      eprint={1704.00028},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{
  ye2018gan,
  title={GAN Quality Index (GQI) By GAN-induced Classifier},
  author={Yuancheng Ye and Lijuan Wang and Yue Wu and Yinpeng Chen and Yingli Tian and Zicheng Liu and Zhengyou Zhang},
  year={2018},
  url={https://openreview.net/forum?id=S1CIev1vM}
}


@inproceedings{37648,
title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year	= {2011},
URL	= {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}



@misc{johnson2016perceptual,
      title={Perceptual Losses for Real-Time Style Transfer and Super-Resolution}, 
      author={Justin Johnson and Alexandre Alahi and Li Fei-Fei},
      year={2016},
      eprint={1603.08155},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{goodfellow2017nips,
      title={NIPS 2016 Tutorial: Generative Adversarial Networks}, 
      author={Ian Goodfellow},
      year={2017},
      eprint={1701.00160},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{taigman2016unsupervised,
      title={Unsupervised Cross-Domain Image Generation}, 
      author={Yaniv Taigman and Adam Polyak and Lior Wolf},
      year={2016},
      eprint={1611.02200},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{donahue2017adversarial,
      title={Adversarial Feature Learning}, 
      author={Jeff Donahue and Philipp Krähenbühl and Trevor Darrell},
      year={2017},
      eprint={1605.09782},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dumoulin2017adversarially,
      title={Adversarially Learned Inference}, 
      author={Vincent Dumoulin and Ishmael Belghazi and Ben Poole and Olivier Mastropietro and Alex Lamb and Martin Arjovsky and Aaron Courville},
      year={2017},
      eprint={1606.00704},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@misc{liu2016coupled,
      title={Coupled Generative Adversarial Networks}, 
      author={Ming-Yu Liu and Oncel Tuzel},
      year={2016},
      eprint={1606.07536},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shrivastava2017learning,
      title={Learning from Simulated and Unsupervised Images through Adversarial Training}, 
      author={Ashish Shrivastava and Tomas Pfister and Oncel Tuzel and Josh Susskind and Wenda Wang and Russ Webb},
      year={2017},
      eprint={1612.07828},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{long2015fully,
      title={Fully Convolutional Networks for Semantic Segmentation}, 
      author={Jonathan Long and Evan Shelhamer and Trevor Darrell},
      year={2015},
      eprint={1411.4038},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{liu2018unsupervised,
      title={Unsupervised Image-to-Image Translation Networks}, 
      author={Ming-Yu Liu and Thomas Breuel and Jan Kautz},
      year={2018},
      eprint={1703.00848},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{fu2018geometryconsistent,
      title={Geometry-Consistent Generative Adversarial Networks for One-Sided Unsupervised Domain Mapping}, 
      author={Huan Fu and Mingming Gong and Chaohui Wang and Kayhan Batmanghelich and Kun Zhang and Dacheng Tao},
      year={2018},
      eprint={1809.05852},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lee2019drit,
      title={DRIT++: Diverse Image-to-Image Translation via Disentangled Representations}, 
      author={Hsin-Ying Lee and Hung-Yu Tseng and Qi Mao and Jia-Bin Huang and Yu-Ding Lu and Maneesh Singh and Ming-Hsuan Yang},
      year={2019},
      eprint={1905.01270},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{heusel2018gans,
      title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}, 
      author={Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
      year={2018},
      eprint={1706.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{radford2016unsupervised,
      title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}, 
      author={Alec Radford and Luke Metz and Soumith Chintala},
      year={2016},
      eprint={1511.06434},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{yu2016lsun,
      title={LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop}, 
      author={Fisher Yu and Ari Seff and Yinda Zhang and Shuran Song and Thomas Funkhouser and Jianxiong Xiao},
      year={2016},
      eprint={1506.03365},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{6065551,  author={C. {Liu} and F. {Yin} and Q. {Wang} and D. {Wang}},  booktitle={2011 International Conference on Document Analysis and Recognition},   title={ICDAR 2011 Chinese Handwriting Recognition Competition},   year={2011},  volume={},  number={},  pages={1464-1469},  doi={10.1109/ICDAR.2011.291}}




@misc{zhao2017energybased,
      title={Energy-based Generative Adversarial Network}, 
      author={Junbo Zhao and Michael Mathieu and Yann LeCun},
      year={2017},
      eprint={1609.03126},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{thanhtung2020catastrophic,
      title={On Catastrophic Forgetting and Mode Collapse in Generative Adversarial Networks}, 
      author={Hoang Thanh-Tung and Truyen Tran},
      year={2020},
      eprint={1807.04015},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{metz2017unrolled,
      title={Unrolled Generative Adversarial Networks}, 
      author={Luke Metz and Ben Poole and David Pfau and Jascha Sohl-Dickstein},
      year={2017},
      eprint={1611.02163},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{726791,  author={Y. {Lecun} and L. {Bottou} and Y. {Bengio} and P. {Haffner}},  
journal={Proceedings of the IEEE},   
title={Gradient-based learning applied to document recognition},   
year={1998},  volume={86},  
number={11},  pages={2278-2324},  doi={10.1109/5.726791}}

@techreport{susskind2010toronto,
  title={The Toronto face dataset},
  author={Susskind, Joshua and Anderson, Adam and Hinton, Geoffrey E},
  year={2010},
  institution={Technical Report UTML TR 2010-001, U. Toronto}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}



@misc{bengio2012better,
      title={Better Mixing via Deep Representations}, 
      author={Yoshua Bengio and Grégoire Mesnil and Yann Dauphin and Salah Rifai},
      year={2012},
      eprint={1207.4404},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{bengio2014deep,
      title={Deep Generative Stochastic Networks Trainable by Backprop}, 
      author={Yoshua Bengio and Eric Thibodeau-Laufer and Guillaume Alain and Jason Yosinski},
      year={2014},
      eprint={1306.1091},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{cordts2016cityscapes,
      title={The Cityscapes Dataset for Semantic Urban Scene Understanding}, 
      author={Marius Cordts and Mohamed Omran and Sebastian Ramos and Timo Rehfeld and Markus Enzweiler and Rodrigo Benenson and Uwe Franke and Stefan Roth and Bernt Schiele},
      year={2016},
      eprint={1604.01685},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{article,
author = {Eitz, Mathias and Hays, James and Alexa, Marc},
year = {2012},
month = {07},
pages = {},
title = {How Do Humans Sketch Objects?},
volume = {31},
journal = {ACM Transactions on Graphics - TOG},
doi = {10.1145/2185520.2185540}
}

@online{noauthor_cs231n_nodate,
	title = {{CS}231n Convolutional Neural Networks for Visual Recognition},
	url = {https://cs231n.github.io/convolutional-networks/#overview},
	urldate = {2021-03-04},
}


@article{Creswell_2018,
   title={Generative Adversarial Networks: An Overview},
   volume={35},
   ISSN={1053-5888},
   url={http://dx.doi.org/10.1109/MSP.2017.2765202},
   DOI={10.1109/msp.2017.2765202},
   number={1},
   journal={IEEE Signal Processing Magazine},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
   year={2018},
   month={Jan},
   pages={53–65}
}


@article{articleCNNs,
author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard and Togashi, Kaori},
year = {2018},
month = {06},
pages = {},
title = {Convolutional neural networks: an overview and application in radiology},
volume = {9},
journal = {Insights into Imaging},
doi = {10.1007/s13244-018-0639-9}
}

@misc{manisha2019generative,
      title={Generative Adversarial Networks (GANs): What it can generate and What it cannot?}, 
      author={P Manisha and Sujit Gujar},
      year={2019},
      eprint={1804.00140},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhu2018generative,
      title={Generative Visual Manipulation on the Natural Image Manifold}, 
      author={Jun-Yan Zhu and Philipp Krähenbühl and Eli Shechtman and Alexei A. Efros},
      year={2018},
      eprint={1609.03552},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{6909426,
  author={A. {Yu} and K. {Grauman}},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Fine-Grained Visual Comparisons with Local Learning}, 
  year={2014},
  volume={},
  number={},
  pages={192-199},
  doi={10.1109/CVPR.2014.32}}


@misc{li2016precomputed,
      title={Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks}, 
      author={Chuan Li and Michael Wand},
      year={2016},
      eprint={1604.04382},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{oord2019representation,
      title={Representation Learning with Contrastive Predictive Coding}, 
      author={Aaron van den Oord and Yazhe Li and Oriol Vinyals},
      year={2019},
      eprint={1807.03748},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{LeCun.2015,
 abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 year = {2015},
 title = {Deep learning},
 pages = {436--444},
 volume = {521},
 number = {7553},
 issn = {1476-4687},
 journal = {Nature},
 doi = {10.1038/nature14539}
}


@misc{russakovsky2015imagenet,
      title={ImageNet Large Scale Visual Recognition Challenge}, 
      author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
      year={2015},
      eprint={1409.0575},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@incollection{NIPS2012_4824,
  added-at = {2016-11-14T12:05:24.000+0100},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  biburl = {https://www.bibsonomy.org/bibtex/2886c491fe45049fee3c9660df30bb5c4/albinzehe},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  interhash = {74bbb5dea5afb1b088bd10e317f1f0d2},
  intrahash = {886c491fe45049fee3c9660df30bb5c4},
  keywords = {cnn deeplearning ma-zehe neuralnet},
  pages = {1097--1105},
  publisher = {Curran Associates, Inc.},
  timestamp = {2016-11-14T12:05:24.000+0100},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  year = 2012
}



% This file was created with Citavi 6.4.0.35

@article{Hubel.1968,
 abstract = {1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded.2. Evidence is presented for at least two independent systems of columns extending vertically from surface to white matter. Columns of the first type contain cells with common receptive-field orientations. They are similar to the orientation columns described in the cat, but are probably smaller in cross-sectional area. In the second system cells are aggregated into columns according to eye preference. The ocular dominance columns are larger than the orientation columns, and the two sets of boundaries seem to be independent.3. There is a tendency for cells to be grouped according to symmetry of responses to movement; in some regions the cells respond equally well to the two opposite directions of movement of a line, but other regions contain a mixture of cells favouring one direction and cells favouring the other.4. A horizontal organization corresponding to the cortical layering can also be discerned. The upper layers (II and the upper two-thirds of III) contain complex and hypercomplex cells, but simple cells are virtually absent. The cells are mostly binocularly driven. Simple cells are found deep in layer III, and in IV A and IV B. In layer IV B they form a large proportion of the population, whereas complex cells are rare. In layers IV A and IV B one finds units lacking orientation specificity; it is not clear whether these are cell bodies or axons of geniculate cells. In layer IV most cells are driven by one eye only; this layer consists of a mosaic with cells of some regions responding to one eye only, those of other regions responding to the other eye. Layers V and VI contain mostly complex and hypercomplex cells, binocularly driven.5. The cortex is seen as a system organized vertically and horizontally in entirely different ways. In the vertical system (in which cells lying along a vertical line in the cortex have common features) stimulus dimensions such as retinal position, line orientation, ocular dominance, and perhaps directionality of movement, are mapped in sets of superimposed but independent mosaics. The horizontal system segregates cells in layers by hierarchical orders, the lowest orders (simple cells monocularly driven) located in and near layer IV, the higher orders in the upper and lower layers.},
 author = {Hubel, D. H. and Wiesel, T. N.},
 year = {1968},
 title = {Receptive fields and functional architecture of monkey striate cortex},
 keywords = {Animals;Color Perception;Evoked Potentials;Haplorhini;Light;Motion Perception;Occipital Lobe/anatomy {\&} histology/physiology;Retina/physiology;Vision, Ocular/physiology;Visual Fields},
 pages = {215--243},
 volume = {195},
 number = {1},
 issn = {0022-3751},
 journal = {The Journal of physiology},
 doi = {10.1113/jphysiol.1968.sp008455},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/4966457},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1557912}
}


% This file was created with Citavi 6.4.0.35

@article{Fukushima.1980,
 abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by ``learning without a teacher'', and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname ``neocognitron''. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of ``S-cells'', which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of ``C-cells'' similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any ``teacher'' during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
 author = {Fukushima, Kunihiko},
 year = {1980},
 title = {Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
 pages = {193--202},
 volume = {36},
 number = {4},
 issn = {1432-0770},
 journal = {Biological Cybernetics},
 doi = {10.1007/BF00344251}
}


@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@misc{lin2014network,
      title={Network In Network}, 
      author={Min Lin and Qiang Chen and Shuicheng Yan},
      year={2014},
      eprint={1312.4400},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}


@article{Kang_2020,
   title={Unsupervised Adaptation for Synthetic-to-Real Handwritten Word Recognition},
   ISBN={9781728165530},
   url={http://dx.doi.org/10.1109/WACV45572.2020.9093392},
   DOI={10.1109/wacv45572.2020.9093392},
   journal={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)},
   publisher={IEEE},
   author={Kang, Lei and Rusinol, Marcal and Fornes, Alicia and Riba, Pau and Villegas, Mauricio},
   year={2020},
   month={Mar}
}




@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{10.5555/3104322.3104425,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
year = {2010},
isbn = {9781605589077},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these "Stepped Sigmoid Units" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {807–814},
numpages = {8},
location = {Haifa, Israel},
series = {ICML'10}
}



@misc{ramachandran2017searching,
      title={Searching for Activation Functions}, 
      author={Prajit Ramachandran and Barret Zoph and Quoc V. Le},
      year={2017},
      eprint={1710.05941},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

 @InProceedings{pmlr-v15-glorot11a, title = {Deep Sparse Rectifier Neural Networks}, author = {Xavier Glorot and Antoine Bordes and Yoshua Bengio}, booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, pages = {315--323}, year = {2011}, editor = {Geoffrey Gordon and David Dunson and Miroslav Dudík}, volume = {15}, series = {Proceedings of Machine Learning Research}, address = {Fort Lauderdale, FL, USA}, month = {11--13 Apr}, publisher = {JMLR Workshop and Conference Proceedings}, pdf = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf}, url = {http://proceedings.mlr.press/v15/glorot11a.html}, abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training. [pdf]} } 