%\noindent
\justifying
\setlength{\parskip}{1em}

This chapter aims to develop a better understanding of fundamental concepts required to understand this thesis. It discusses the mathematics and working principle of the \acp{GAN}. It also discusses \acp{CNN} and its layers. The formulation and architecture of \acp{GAN} is explained in section \ref{GenerativeAdversarialNetworks}. In section \ref{CNNs}, layers like convolution layer, activation layer, pooling layer, and fully connected layer have briefly explained.


\section{Generative Adversarial Networks (GANs)}\label{GenerativeAdversarialNetworks}

\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.25]{images/Fundamentals/GANTrainingintuition.png}
	    \caption[Intuitive example of \ac{GAN} training progress.]{Intuitive example of \ac{GAN} training progress.}
	    \label{fig:GANTrainingintuition}
	    \end{center}
\end{figure}

Ian J. Goodfellow et al.\cite{goodfellow2014generative} proposed \acp{GAN}. It has two models in its architecture, one is generator, and another is discriminator. Authors mentioned both can be implemented using multilayer networks. Normally, the term multilayer networks indicated for \acp{CNN} or \acp{ANN}. Let's try to understand the function of \acp{GAN} intuitively. Consider generator is a forger who creates fake images of currency, with the intention of making them realistic as much as possible. Furthermore, the discriminator is an expert, which receives both forged and real images, and distinguishes between real and forged images. The discriminator has access to images generated by the generator and real images present in the dataset. The generator generates fake images without having access to the real images using random noise distribution. Both generator and discriminator are trained simultaneously. The discriminator learns by the error signal provided by the ground truth of distinguishing whether the image came from the dataset of real images or from the generator. The generator learns using the same error signal given by the discriminator to produce a better quality of forged or fake images. It is a setup where both generator and discriminator are competing with each other.

In figure \ref{fig:GANTrainingintuition} an intuitive example of \ac{GAN} training process is displayed. During the initial stage of the training, images produced by the generator are easily distinguishable by the discriminator as fake images. After a certain number of iterations, the quality images generated by the generator increases by the feedback error signal given by the discriminator. Also, the discriminator gets smarter and smarter to distinguish fake images and real images, like mentioned earlier both models are trained simultaneously. But at a certain point generator starts to produce realistic images which the discriminator classifies as real. In figure \ref{fig:GANStructure}, we can see GAN in action. Let us have a look into the GAN's core architecture. As described earlier, the task of the GAN is to generate fake samples. Hence, the training dataset has a set of real data samples, from which the generator learns to create fake samples that are similar to the real samples. This set of real data samples serves input $X$ to the discriminator $D$. The random noise vector $Z$ retrieved from the random noise distribution serves as an input to the generator to produce fake samples. The generator $G$ takes $Z$ as an input and outputs a fake sample $X'$. Its goal is to create fake samples that are indistinguishable from the real samples from the training dataset. The discriminator $D$ takes input from real data sample $X$ that are present in the training dataset and fake samples $X'$ generated from the generator $G$. For each sample, it determines and outputs the probability of the sample that is real. For every discriminator's prediction, 
The classification error is backpropagated to update both generator and discriminator during iterative training. The discriminator's weights are updated to maximize classification accuracy which means, maximizing the probability of correct prediction $X$ as real and $X'$ as fake. The generator's weights are updated to maximize the probability that the discriminator misclassifies $X'$ as real.


\vspace*{0.5cm}
\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.30]{images/Fundamentals/GANStructure.png}
	    \caption[Overview of core \ac{GAN} architecture.]{Overview of core \ac{GAN} architecture along with the generator's and discriminator's inputs, outputs, and their interactions.}
	    \label{fig:GANStructure}
	    \end{center}
\end{figure}


Now let's try to understand the mathematics behind the \acp{GAN}. For learning the generator’s distribution $p_g$ over data $x$, the input noise variable defined as $p_z(z)$. The generator $G$ and discriminator $D$ are the differentiable functions represented by multilayer networks with parameters $\theta_g$ and $\theta_d$ respectively. The mapping function between from some representation space, called, the latent space to the space of data, represented by $G(z; \theta_g)$. The $D(x; \theta_d)$ is a mapping function that maps data $x$ to the probability that it came from the real data distribution rather than generator distribution $p_g$. Basically, $D(x)$ represents the likelihood of $x$ came from the data rather thatm $p_g$. $D(x; \theta_d)$ outputs a single scalar value between $[0,1]$. $D$ is trained to maximize the probability of correctly labeling both training examples and data generated by the $G$. Usually, when the generator is training, the discriminator does not train and vice versa. This means for a fixed generator $G$, the discriminator is trained to classify data as either being from the real data distribution (real, probability close to one) or from the fixed generator(fake, probability close to zero). After certain iterators of the training, when the discriminator is optimal, it can be frozen. Following, the generator $G$ will be continued to be trained to lower the accuracy of the discriminator. After training, if the generator can match the real data distribution, then the discriminator maximally confused, will predict 0.5 probability for its inputs. In practice, the discriminator is may not be trained till it is optimal \cite{Creswell_2018}. Furthermore, simultaneously $G$ is being trained to minimize $log(1 - D(G(z))$. Simply put, $D$ and $G$ play the two-player minimax game with the objective function $\mathcal{L}_{GAN}(G, D)$:


\begin{equation}\label{ganObjectiveFunction}
\underset{G}{\min}\ \underset{D}{\max}\ \mathcal{L}_{GAN}(D, G) = E_{x\sim p_{data}(x)}[log D(x)] + E_{z\sim p_z(z)}[log(1 - D(G(z)))].
\end{equation}


Authors mentioned, in practice, the equation \ref{ganObjectiveFunction} may not give enough gradient for $G$ to learn well. During Early in learning phase, when $G$ is poor, $D$ can reject samples with high confidence because they are clearly distinct from the training data. In this case, term $log(1 - D(G(z)))$ in equation \ref{ganObjectiveFunction} saturates very quickly. Hence, we can train $G$ to maximize $log D(G(z))$ rather than training $G$ to minimize $log(1 - D(G(z)))$. This objective function leadsto the same fixed point of the dynamics of $G$ and $D$ by providing much stronger gradients early in learning \cite{goodfellow2014generative}.



\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.49]{images/Fundamentals/GANTraining.jpg}
	    \caption[Illustration of \acp{GAN} converging to match generated data distribution $p_g$ to real data distribution $p_{data}$.]{Illustration of \acp{GAN} converging to match generated data distribution $p_g$ to real data distribution $p_{data}$ \cite{goodfellow2014generative}.}
	    \label{fig:GANTraining}
	    \end{center}
\end{figure}


In figure \ref{fig:GANTraining}, \acp{GAN} converging to match generated data distribution $p_g$ to real data distribution $p_{data}$. While training \acp{GAN}, discriminative distribution ($D$, blue, dashed line) is simultaneously updated, so it will discriminate samples from the real data distribution (black, dotted line) $p_x$ from those of the generated data distribution $p_g$ (G, green, solid line). The lower horizontal line represents the domain noise distribution $p_z$ from which $z$ is sampled uniformly. The horizontal line above represents the part of the domain of real data $x$. The upward arrows depict the mapping of $x = G(z)$, which creates the non-uniform generated data distribution $p_g$ on transformed samples. (a) Consider, generator $G$ and discriminator $D$ are on the verge of convergence, $p_g$ is almost similar to $p_{data}$ and $D$ is a partially accurate classifier. (b) Slowly, discriminator $D$ trained further to distinguish real data samples from generated data samples. For a fixed generator, there is an optimal discriminator, $D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$. (c) The generator $G$ is updated using gradients that are backpropagated from discriminator $D$ and makes $G(z)$ to flow to regions that are more likely to be classified as real data. The parameters of the generator are updated, while the parameters of the discriminator are fixed and vice versa. (d) After several steps of training, the generator, $G$, is optimal where $p_g = p_{data}$, which is equivalent to the optimal discriminator $D$ predicting 0.5 for all samples drawn from $x$, at this stage discriminator $D$ is maximally confused and will not able to distinguish real data samples from generated data samples, i.e. $D(x) = \frac{1}{2}$ \cite{goodfellow2014generative}.





\newpage

\subsection{\ac{GAN} Training}

This section presents the algorithm of the \ac{GAN} and in the figure \ref{fig:generatorAndDiscriminatorTraining}, we can see the pictorial representation of the algorithm. The GAN training algorithm is divided into two sections. These two sections are discriminator training and generator training. In figure \ref{fig:generatorAndDiscriminatorTraining} shows the same GAN network in different stages of the training process at distinct time points. For example, while training generator, the discriminator is not training and vice versa. Hence, the training dataset of real data samples is grayed out or disabled in the section when the generator is getting trained. While training discriminator both generated samples from the generator and real samples are used as an input. In the following sections describe generator's and discriminator's architecture and their training process. Further, the \ac{GAN} training algorithm has been described in the form of pseudo code.

\subsubsection{The Discriminator Architecture}\label{TheDiscriminatorSubSection}

The discriminator in a \ac{GAN} is a binary classifier. It attempts to classify real data samples from fake data samples generated by the generator. It outputs the probability of input being a real data sample. The discriminator can be implemented using a multilayer neural network which is suitable to the kind of data it's classifying. If the discriminator is classifying images the \ac{CNN} could be a good choice \cite{radford2016unsupervised}. The discriminator's training data come from the two resources, training dataset or collection of real data samples and fake data samples generated by the generator. During \ac{GAN} training, the discriminator is trained by both real data samples and fake data samples generated by the generator. The discriminator is penalized for misclassifying a real data sample as fake or a fake data sample as real. Such classification error is called discriminator loss. The discriminator loss is backpropagated to update the weights of the discriminator network. The training process of the discriminator $D$ using backpropagation illustrated in figure \ref{fig:discriminatorTraining}.


\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.45]{images/Fundamentals/discriminatorTraining.png}
	    \caption[Illustration of the training of the discriminator $D$ using backpropagation.]{Illustration of the training of the discriminator $D$ using backpropagation.}
	    \label{fig:discriminatorTraining}
	    \end{center}
\end{figure}

\subsubsection{The Generator Architecture}\label{TheGeneratorSubSection}


The generator produces fake samples using random noise vectors sampled from the uniform random noise distribution. As described earlier, the discriminator's weights are frozen while training the generator. This means the discriminator is not training while the generator is generating fake samples and vice versa. The generator can be implemented using a multilayer neural network which is suitable for the kind of data it's generating. If the generator is generating images using the random noise distribution, the \ac{CNN} could be a good choice \cite{radford2016unsupervised}. The generator aims to produce fake samples that are as realistic as possible. But when the generator for fails to fool the discriminator or when the discriminator classifies the generated sample as fake, then it is penalized with classification error. Such classification error is called generator loss. The generator loss is backpropagated to update the weights of the generator. The training process of the generator $G$ using backpropagation illustrated in figure \ref{fig:generatorTraining}.

\vspace*{0.5cm}
\begin{figure}[H]
    \begin{center}
	\includegraphics[scale=0.30]{images/Fundamentals/generatorTraining.png}
	\caption[Illustration of the training of the generator $G$ using backpropagation.]{Illustration of the training of the generator $G$ using backpropagation.}
	\label{fig:generatorTraining}
	\end{center}
\end{figure}




\subsubsection{\ac{GAN} Training Algorithm}

\begin{algorithm}[H]
\For{each training iteration}{
 \BlankLine
 \BlankLine
 \BlankLine
	\textbf{1. Train the Discriminator:}
	\BlankLine
	\BlankLine
		\Indp
		a) Get a random real data sample $X$ from the training dataset. \\
		\BlankLine
		b) Get a random noise vector $Z$ from the random noise distribution, pass it thorough the Generator and create a fake sample $X'$. \\
		\BlankLine
		c) Classify $X$ and $X'$ using the Discriminator.\\
		\BlankLine
		d) Backpropagate the calculated classification error to update the Discriminator's weights to \textit{minimize} classification error.\\
	\BlankLine
	\BlankLine
	\BlankLine
	\Indm
	\textbf{2. Train the Generator:}
	\BlankLine
	\BlankLine
		\Indp
		a) Get a random noise vector $Z$ from the random noise distribution, pass it thorough the Generator and create a fake sample $X'$. \\
		\BlankLine
		b) Classify $X'$ using the Discriminator.\\
		\BlankLine
		c) Backpropagate the calculated classification error to update the Generator’s weights to \textit{maximize} the Discriminator’s error.\\
\BlankLine
\BlankLine
\BlankLine
}	
\caption{GAN Training Algorithm \cite{langr2019gans}.}
\label{alg:ganTrainingAlg}
\end{algorithm}



\newpage

\section{Convolution Neural Networks}\label{CNNs}


In recent years in the field of machine learning, drastic improvements have occurred to increase the performance of machine learning models. Also, numerous deep learning techniques like \acp{ANN} are evolved significantly. These biologically inspired neural networks were able to exceed the performance compared to the traditional machine learning techniques to solve complex problems \cite{oshea2015introduction}. The most successful image-driven pattern recognition technique among \acp{ANN} is \acp{CNN} \cite{oshea2015introduction}. Nowadays, \acp{CNN} are used to solve difficult image recognition, image classification, and object detection tasks. The \acp{CNN} have been a popular method because of its extraordinary results at object recognition competition known as the \ac{ILSVRC} in 2012 for solving computer vision tasks. \ac{CNN} is a kind of deep learning technique for processing data that has a grid pattern, for example, images. \acp{CNN} are inspired by the early findings in the study of biological vision, especially, organization of the animal visual cortex [\cite{Hubel.1968}, \cite{Fukushima.1980}, \cite{10.5555/3153997}] and designed to automatically and adaptively learn spatial hierarchies of features, from low-level to high-level patterns \cite{10.5555/3153997}. It is composed of various building blocks, such as convolution layers, pooling layers, and fully connected layers. As shown in figure \ref{fig:CNNBuildingBlocks}, the first two layers are convolution and pooling layers. They perform feature extraction. whereas the third, a fully connected layer, maps the extracted features into the final output, such as classification \cite{articleCNNs}. Let us have a look at each layer in the following sections.




\vspace*{0.3cm}
\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.59]{images/Fundamentals/CNNBuildingBlocks.JPG}
	    \caption[Overview of \ac{CNN} architecture and its training process.]{Overview of \ac{CNN} architecture and its training process. \acp{CNN} is a combination of several building blocks like convolution layers, pooling layers, and fully connected layers. These building blocks are stacked upon each other. The \acp{CNN} is trained using the training dataset, the input data is fed in the forward direction through the network. The process of feeding data in the forward direction to the \ac{CNN} is called forward propagation. Each layer accepts the input data, processes it as per the activation function like ReLU (Rectified Linear Unit) (figure \ref{fig:ActivationFunctions}), and passes it to the successive layer. Using a loss function through forward propagation on a training dataset, a model’s performance under particular kernels and weights is calculated. The learnable parameters, for example, weights and kernels, are updated as per the loss value through backpropagation using a gradient descent optimization algorithm \cite{ruder2017overview}.}
	    \label{fig:CNNBuildingBlocks}
	    \end{center}
\end{figure}





\subsection{Convolution Layer}
The convolution layer is a basic component of the \ac{CNN} architecture that performs feature extraction. It is typically a combination of linear and nonlinear operations like convolution operation and activation function. It is one of the core building blocks of \acp{CNN}. Also, it is responsible for most of the heavy computations. A convolution layer plays an important role in \ac{CNN}, it performs mathematical operations like convolution, a specialized type of linear operation. The digital images store pixel values in a \ac{2D} grid, i.e., an array of numbers as shown in figure \ref{fig:Convolution}. The small grid of parameters called the kernel, an optimizable feature extractor, is applied at each image position \cite{articleCNNs}, which makes \acp{CNN} highly efficient for image processing, feature extraction, since a feature could occur at any location in the image. The layers are connected, one layer feeds its output to the next layer. The extracted features can hierarchically and progressively become more complex \cite{articleCNNs}. Training is the process of optimizing parameters such as kernels which minimize the difference between outputs and ground truth labels through an optimization algorithm called backpropagation \cite{Goodfellow-et-al-2016} and gradient descent \cite{ruder2017overview}, among others. 

For feature extraction linear operation, convolution is used, where a small array of numbers, called a kernel, is applied across the input, which is an array of numbers, called a tensor. An element-wise product between kernel's each element and the input tensor is calculated at each location of the tensor and summed to obtain the output value in the corresponding position of the output tensor, called a feature map (figure \ref{fig:Convolution}a-c) \cite{articleCNNs}. 
This procedure is repeated by applying multiple kernels to create an arbitrary number of feature maps, which describe different characteristics of the input tensors \cite{articleCNNs}. The different kernels can be considered as different feature extractors. Two important hyperparameters that represent the convolution operation are the size and number of kernels. The size is typically 3 × 3, but sometimes 5 × 5 or 7 × 7, depends on the requirement. The number of kernels is arbitrary, and determines the depth of output feature maps. The above-mentioned convolution operation prevents the center of each kernel from overlapping the input tensor's outermost element. And the output feature map's height and width are reduced compared to the input tensor. To address this issue, the padding, predominantly zero-padding technique is used where rows and columns of zeros are added on each side of the input tensor, to fit the center of a kernel on the outermost element and keep the same spatial dimension through the convolution operation (figure \ref{fig:ConvolutionZeroPadding}). Modern \ac{CNN} architectures normally employ zero padding to retain spatial dimensions to apply more further layers. Each successive feature map would get smaller after the successive convolution operation without zero padding. A stride is the distance between two successive kernel positions, and it also defines the convolution operation. A stride of 1 is the most common choice; however, a stride greater than 1 is sometimes used to achieve feature map downsampling. A pooling operation, as defined in section \ref{PoolingLayer}, is an alternative technique for downsampling. 


\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.60]{images/Fundamentals/ConvolutionZeroPadding.JPG}
	    \caption[A Convolution Operation With Zero Padding.]{Illustration of a convolution operation with zero padding to retain spatial dimensions. Note that an input dimension of $5 \times 5$ is retained in the generated output feature map. In this example, kernel size is set to $3 \times 3$, and stride is set to $1$ \cite{articleCNNs}.}
	    \label{fig:ConvolutionZeroPadding}
	    \end{center}
\end{figure}


\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.40]{images/Fundamentals/Convolution.JPG}
	    \caption[An illustration of Convolution Operation.]{\textbf{a–c} An illustration of convolution operation with no padding. In this example, kernel size is set to $3 \times 3$, and stride is set to $1$. A kernel is applied across the input tensor, and an element-wise product between each element of the kernel and the input tensor is calculated at each location and summed to obtain the output value in the corresponding position of the output tensor, called a feature map \cite{articleCNNs}.}
	    \label{fig:Convolution}
	    \end{center}
\end{figure}


\subsubsection{Activation Functions}


\acp{ANN} are inspired by biological neural networks present in the animal brain. Before constructing any \ac{ANN}, it is important to understand the artificial neuron model. In the figure \ref{fig:artificialNeuron} schematic diagram of an artificial neuron is illustrated. A biological neuron gets excited when other neurons with different weights send electrical signals to it. The value of the electrical signal should be big enough to excite the neuron. Otherwise, it will be in an inactive state. In the figure \ref{artificialNeuron} schematic diagram of an artificial neuron is illustrated. Where $\{X_1, X_2, X_3, ..., X_n\}$ are the inputs to the artificial neuron, $\{W_1, W_2, W_3, ..., W_n\}$ are the weights corresponding to the inputs. $b$ is the bias. The summation symbol represents the addition unit. The addition unit gets the linear weight sum $Z$ of the inputs and bias. Dot product between inputs and weights performed before addition. If $X = [X_1, X_2, X_3, ..., X_n]  \in R^{n}$  and  $W = [W_1, W_2, W_3, ..., W_n] \in R^{n}$, then output $Z$ is represented as

\begin{equation}\label{linearRegression}
Z=X{W}^\intercal + b.
\end{equation}

\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.30]{images/Fundamentals/ann.png}
	    \caption[Simple Neural Network.]{Simple Neural Network.}
	    \label{fig:ann}
	    \end{center}
\end{figure}

The function $f$ is activation function. It is used to excite the response state of biological neurons and obtain output $Y$
\begin{equation}\label{artificialNeuron}
Y = f(Z).
\end{equation}


The data is fed to the input layer of the neural network, the input undergoes the linear operation. Later, activation functions are applied to it in the hidden layers, and output is produced. In neural networks the hidden layer lies between input layer and output layer. In figure \ref{fig:ann} simple neural network is illustrated. The activation function is applied to the outputs of a linear operation like convolution. The activation functions important while constructing any neural network. They are mathematical functions attached to the neurons. Also, they tell which of the neuron is excited or triggered in each layer of neural networks. The purpose of the activation function is to introduce non-linearity in the neural network.

\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.30]{images/Fundamentals/artificialNeuron.png}
	    \caption[Illustration of Artificial Neuron.]{Illustration of Artificial Neuron.}
	    \label{fig:artificialNeuron}
	    \end{center}
\end{figure}


The equation \ref{linearRegression} performs a linear operation. This linear function gets repeated every hidden layer of the neural network. A combination of such linear functions also a linear function, equivalent to all the hidden layers collapsed into a single linear function performing linear regression. Hence, all the hidden layers become useless. Even if linear functions are easy to use, but they fail to learn complex patterns present in the data like images, speech, and videos. Hence, nonlinear activation functions are used, while constructing neural networks. The nonlinear activation functions are differentiable, and they make gradient descent optimization (backpropagation) possible. Backpropagation minimizes the error and enhances the accuracy and performance of the neural network. The nonlinear functions like the sigmoid and hyperbolic tangent (tanh) functions were used previously because they are mathematical representations of biological neuron behavior. The rectified linear unit is now the most commonly used nonlinear activation function (ReLU) , which simply computes the function: $f(x) = \max(0, x)$ (figure \ref{fig:ActivationFunctions}) [\cite{LeCun.2015}, \cite{NIPS2012_c399862d}, [\cite{10.5555/3104322.3104425}], [\cite{ramachandran2017searching}], \cite{pmlr-v15-glorot11a}].

\vspace*{0.5cm}

\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.42]{images/Fundamentals/ActivationFunctions.jpg}
	    \caption[Most common nonlinear activation functions used while constructing Neural Networks.]{Most common nonlinear activation functions used while constructing Neural Networks: \textbf{a)} rectified linear unit (ReLU), \textbf{b)} sigmoid, and \textbf{c)} hyperbolic tangent (tanh) \cite{articleCNNs}.}
	    \label{fig:ActivationFunctions}
	    \end{center}
\end{figure}

\subsection{Pooling Layer}\label{PoolingLayer}
A pooling layer performs downsampling on feature maps to gradually reducing the spatial dimensionality, which leads to the reduction of the number of parameters and computational complexity of the neural network and controlling overfitting. Downsampling introduces translation invariance to minor shifts and distortions \cite{goodfellow2017deep}. Downsampling of feature maps can be accomplished by using convolution layers by increasing the stride of the convolution operation across the image. But the robust and common approach of downsampling is to use a pooling layer \cite{goodfellow2017deep}. Similar to convolution operations, it used hyperparameters like filter size, stride, and padding. Also, it is common to periodically insert a pooling layer in between successive convolution layers while constructing neural networks. There two common types of pooling methods one is max pooling the other is average pooling. The max-pooling considers the most activated (maximum value) value in each input patch of the feature map. The average pooling averages values in each input patch of the feature map.

\subsubsection{Max Pooling}
Max pooling is the most common and popular type of pooling operation. The max-pooling operation is independently operated at every depth slice of the input and resized spatially. Commonly, in max-pooling filters of size $2 \times 2$ applied with a stride of 2. The max-pooling operation extracts small patches of given filter size from the input feature maps and outputs the maximum value in every patch discarding others (figure \ref{fig:PoolingLayer}) \cite{goodfellow2017deep}. The spatial dimension of feature maps is reduced by a factor of two by discarding 75\% of its activations \cite{kumar2018ordinal}. The height and width dimension of the features maps is reduced but the depth dimension remains unchanged. Pooling operations with larger filter sizes are too destructive. It's worth noting that max-pooling layers do not have learnable parameters.

\subsubsection{Global Average Pooling}
There is another type of pooling operation called global average pooling. It performs an extreme type of downsampling. It downsamples a feature map of size height $\times$ width $\times$ depth into a $1 \times 1 \times$ depth array by averaging all the elements present in the feature map by keeping depth dimension unchanged. This operation is applied only once before fully connected layers. There are some benefits of using global average pooling: a)  It reduces the number of learnable parameters. b) allows the CNN to consider inputs of variable size \cite{articleCNNs} \cite{lin2014network}.



\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.50]{images/Fundamentals/PoolingLayer.png}
	    \caption[Illustration of Max Pooling Operation.]{Illustration of max pooling operation with a filter size of $2 \times 2$. No padding, and a stride of 2. Max pooling operation extracts $2 \times 2$ patches from the input tensors, outputs the maximum value in each patch, and discards the rest of the other values, which results in the spatial dimension of an input tensor downsampled by a factor of 2 \cite{articleCNNs}.}
	    \label{fig:PoolingLayer}
	    \end{center}
\end{figure}



\subsection{Fully connected layer}

In neural networks, fully connected layers are those layers where all the inputs from one layer are connected to every neuron of the next layer. The final output feature map of convolution layers or pooling layers is flattened and the output is transformed into a \ac{1D} vector or array of numbers. The flattened output is connected to one or more fully connected layers. The fully connected layers are also called dense layers, where every input is connected to every output by a learnable weight. A fully connected layer performs multiplication between the input and weight matrix and then adds a bias vector. Each fully connected layer is followed by a nonlinear activation function, for example, ReLU. As already described, the nonlinear activation function helps neurons learn complex patterns. The equation \ref{artificialNeuron} represents the function of a fully connected layer. The features extracted using convolution layers and downsampled by pooling layers are mapped by a subset of fully connected layers to the final output of the neural network, for example, probabilities for each class in the classification tasks. Most of the time number of output nodes in the final fully connected layer equals the number of classes. The final fully connected layer's activation function is usually different than others. Each task chooses a suitable activation function. The sigmoid activation function is used in binary classification tasks. For example, logistic regression models the probabilities for binary classification tasks using the sigmoid activation function. The softmax activation function is widely used in multiclass classification tasks. It normalizes output real values from the last fully connected layer to target class probabilities, ranges between 0 and 1, and all values sum to 1 \cite{articleCNNs}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{comment}
\begin{center}
\begin{table}[H]
    \begin{center}
    \begin{tabular}{p{0.40\linewidth} p{0.40\linewidth}} 
        \toprule
        Task & Last layer activation function \\ %[1.0ex] 
        \midrule
        Binary classification & Sigmoid\\ %[1.0ex] 
        \midrule
        Multiclass single-class classification & Softmax \\ %[1.0ex]
        \midrule
        Multiclass multiclass classification & Sigmoid \\ %[1.0ex]
        \midrule
        Regression to continuous values & Identity \\ %[1.0ex]
        \bottomrule
    \end{tabular}
    \caption{A list of commonly applied last layer activation functions for various tasks.}
    \label{table:activationfunction}
    \end{center}
\end{table}
\end{center}
\end{comment}


%Another pooling operation worth noting is a global average pooling \cite{lin2014network}. An extreme type of downsampling is performed by global average pooling. Eventually, global average pooling downsamples a feature map with a size of height $\times$ width into a $1 \times 1$ array by simply taking the average of all the elements in each feature map while maintaining the depth of feature maps. Before the fully connected layers, this operation is usually applied only once \cite{articleCNNs}. The following are the benefits of using global average pooling: (1) it reduces the number of learnable parameters and (2) it allows the \ac{CNN} to accept inputs of variable size. Before the fully connected layers, this operation is usually performed only once. The following are some of the benefits of using global average pooling: (1) the number of learnable parameters is decreased, and (2) allows the CNN to consider inputs of variable size

%In recent years tremendous interest in deep learning has developed. The most successful algorithm among numerous deep learning models is \acp{CNN}. It is a class of artificial neural networks. It has been a prevailing method in solving computer vision tasks since the extraordinary results were shared on the object recognition competition known as the \ac{ILSVRC} in 2012 [\cite{russakovsky2015imagenet}, \cite{NIPS2012_4824}]. It has been a popular method in solving computer vision tasks since the remarkable performance at the object recognition competition known as the \ac{ILSVRC} in 2012 [\cite{russakovsky2015imagenet}, \cite{NIPS2012_4824}]. 
%\footnote{A convolution is a mathematical operation that slides one function over another and measures the integral of their pointwise multiplication. It has deep connections with the Fourier transform and the Laplace transform, and is heavily used in signal processing. Convolutional layers actually use cross-correlations, which are very similar to convolutions (see \url{https://homl.info/76} for more details) \cite{10.5555/3153997}last access: 08.05.2021.}


%\acp{CNN} combinations of several building blocks like convolution layers, pooling layers (e.g., max pooling, global average pooling), and fully connected layers. These building blocks are stacked on each other. With a loss function through forward propagation on a training dataset, a model’s performance under particular kernels and weights is calculated. The learnable parameters, like kernels and weights, are updated as per the loss value through backpropagation using a gradient descent optimization algorithm \cite{ruder2017overview}. The ReLU notation stands for the rectified linear unit. It is an activation function \ref{fig:ActivationFunctions} \cite{articleCNNs}.

\begin{comment}
\begin{center}
\begin{table}
    \begin{tabular}{p{0.25\linewidth} p{0.15\linewidth} p{0.50\linewidth}} 
        \toprule
        & Parameters & Hyperparameters\\ %[1.0ex] 
        \midrule
        Convolution layer & Kernels & Kernel size, number of kernels, stride, padding, activation function \\ %[1.0ex]
        \midrule
        Pooling layer & None & Pooling method, filter size, stride, padding \\ %[1.0ex]
        \midrule
        Fully connected layer & Weights & Number of weights, activation function \\ %[1.0ex]
        \midrule
        Others & & Model architecture, optimizer, learning rate, loss function, mini-batch size, epochs, regularization, weight initialization, dataset splitting\\% [1.0ex]
        \bottomrule
    \end{tabular}
    \caption{A list of parameters and hyperparameters in a convolutional neural network (\ac{CNN}).}
    \label{table:hyperparametersCNN}
\end{table}
\end{center}
\end{comment}

%Max pooling is the most common form of pooling operation, which extracts patches from the input feature maps, outputs the maximum value in each patch, and discards the rest (figure \ref{fig:PoolingLayer}). In practice, a max pooling with a size $2 \times 2$ filter and a stride of 2 is widely used. The spatial dimension of feature maps is reduced by a factor of two. The depth dimension of feature maps, unlike the height and width dimensions, does not change.

\begin{comment}
The discriminator in a \ac{GAN} is a binary classifier. It tries to classify between real data and the data generated by the generator. The discriminator can use any network architecture which is suitable to the kind of data it's classifying. The  training data of the discriminator comes from two sources: a) Real Data Samples. During training, the discriminator uses these samples as positive instances. b) Fake Data Samples generated by the generator. The discriminator uses these samples as negative instances during training. In figure \ref{fig:discriminatorTraining}, the two ``Sample" boxes represent these two data sources feeding into the discriminator.


The generator does not train when the discriminator is training. The generator's weights remain unchanged while it generates samples to train the discriminator. The discriminator is connected to two loss functions. The discriminator completely ignores the generator loss and just uses the discriminator loss during its training. The generator loss is used during generator training to update its weights. The coming section \ref{TheGeneratorSubSection} describes why the generator loss connects to the discriminator. During the discriminator training process: a) Discriminator classifies both real data and fake data generated from the generator. b) The discriminator loss penalizes the discriminator for wrongly classifying a real instance as fake or a fake instance as real. c) Through backpropagation, the discriminator updates its weights using the discriminator loss through the discriminator network.
\end{comment}

\begin{comment}
The generator part of a \ac{GAN} learns to create fake data by receiving backpropagation loss from the discriminator. Slowly it learns and trains to make the discriminator classify its fake output as real. Generator training requires a closer alliance between the generator and the discriminator as compared to the discriminator training requires. The part of the \ac{GAN} that trains the generator includes: a) Random input data. b) Generator network, which transforms the random input data into plausible data. c) Discriminator network, which classifies the generated data. d) Discriminator output. e) Generator loss, which penalizes the generator for failing to fool the discriminator. Neural networks need some form of input data, like an example for classification or to predict about. But what to consider as an input for a neural network that outputs entirely new data instances? In its most fundamental form, a \ac{GAN} takes random noise as its input. The generator then transforms this random noise into a plausible output. By introducing random noise, \ac{GAN} can generate a wide variety of data, sampling from different places in the target distribution. Investigations suggest that the distribution of the noise doesn’t matter much, therefore it is possible to choose something easy to sample from, as a uniform distribution. For simplicity, the distribution from which the noise is sampled is usually of a smaller dimension than the dimensionality of the output distribution. To train a neural network, its weights are updated to reduce the error or loss of its output.  In \ac{GAN}, however, the generator is not directly connected to the loss that is required to update its weights. The discriminator produces the generator loss as the generator feeds into the discriminator network. The generator loss penalizes the generator for generating a sample that the discriminator network classifies as fake. This extra piece of the implementation must be included in backpropagation. The backpropagation adjusts the weights in the appropriate direction by calculating the weight’s impact on the output — how the output would change if you updated the weights. But the impact of a generator weight depends on the discriminator weights it feeds into. So generator loss is backpropagated from the output of the discriminator to the generator. Means gradients flow back through the discriminator into the generator. 


At the same time, the discriminator will not change during generator training. Attempting to hit a moving target would make a complicated problem even difficult for the generator. The generator is trained with the following procedure: 1) Random noise input to the generator. 2) Generator produces output from sampled random noise. 3) The discriminator determines whether the generator output is “Real” or “Fake”. 4) Calculate loss from discriminator classification. 5) Backpropagate the generator loss through both the discriminator and generator to obtain gradients. 6) Use the gradients to update only the generator's weights.
\end{comment}

\begin{comment}
The \ac{GAN} has two training models one is a generator and another is a discriminator. The generator learns to generate plausible data. The discriminator always aims to reject samples produced by the generator as the generated samples are negative training samples for the discriminator. Throughout the training, the discriminator learns to distinguish the generator's fake data from real data. When the generator produces implausible results the discriminator penalizes it. Once the training starts, the generator generates fake data, and the discriminator learns to rejects the data by saying the generator that it's fake data. As training progresses, the generator learns to produce the output that can fool the discriminator. Lastly, if generator training is successful, the discriminator gets bad at telling the difference between real data and fake data generated by the generator. The discriminator starts to classify fake data as real, and its accuracy decreases. Ultimately, the generator will start producing plausible data. Both the generator and the discriminator are neural networks. The generator's output is connected directly to the discriminator's input. The discriminator's classification provides the loss that the generator uses to update its weights using backpropagation.

\subsection{The Discriminator}\label{TheDiscriminatorSubSection}

\vspace*{-0.7cm}
\begin{figure}[H]
        \begin{center}
	    \includegraphics[scale=0.45]{images/discriminatorTraining.png}
	    \caption[Illustartion of the training of the discriminator $D$ using backpropagation.]{Training of the discriminator $D$ using backpropagation.}
	    \label{fig:discriminatorTraining}
	    \end{center}
\end{figure}

The discriminator in a \ac{GAN} is a binary classifier. It tries to classify between real data and the data generated by the generator. The discriminator can use any network architecture which is suitable to the kind of data it's classifying. The  training data of the discriminator comes from two sources: a) Real Data Samples. During training, the discriminator uses these samples as positive instances. b) Fake Data Samples generated by the generator. The discriminator uses these samples as negative instances during training. In figure \ref{fig:discriminatorTraining}, the two ``Sample" boxes represent these two data sources feeding into the discriminator. The generator does not train when the discriminator is training. The generator's weights remain unchanged while it generates samples to train the discriminator. The discriminator is connected to two loss functions. The discriminator completely ignores the generator loss and just uses the discriminator loss during its training. The generator loss is used during generator training to update its weights. The coming section \ref{TheGeneratorSubSection} describes why the generator loss connects to the discriminator. During the discriminator training process: a) Discriminator classifies both real data and fake data generated from the generator. b) The discriminator loss penalizes the discriminator for wrongly classifying a real instance as fake or a fake instance as real. c) Through backpropagation, the discriminator updates its weights using the discriminator loss through the discriminator network.





\subsection{The Generator}\label{TheGeneratorSubSection}

%\vspace*{1.5cm}
\begin{figure}[H]
    \begin{center}
	\includegraphics[scale=0.30]{images/generatorTraining.png}
	\caption[Training Generator $G$ using backpropagation]{Training Generator $G$ using backpropagation.}
	\label{fig:generatorTraining}
	\end{center}
\end{figure}

The generator part of a \ac{GAN} learns to create fake data by receiving backpropagation loss from the discriminator. Slowly it learns and trains to make the discriminator classify its fake output as real. Generator training requires a closer alliance between the generator and the discriminator as compared to the discriminator training requires. The part of the \ac{GAN} that trains the generator includes: a) Random input data. b) Generator network, which transforms the random input data into plausible data. c) Discriminator network, which classifies the generated data. d) Discriminator output. e) Generator loss, which penalizes the generator for failing to fool the discriminator. Neural networks need some form of input data, like an example for classification or to predict about. But what to consider as an input for a neural network that outputs entirely new data instances? In its most fundamental form, a \ac{GAN} takes random noise as its input. The generator then transforms this random noise into a plausible output. By introducing random noise, \ac{GAN} can generate a wide variety of data, sampling from different places in the target distribution. Investigations suggest that the distribution of the noise doesn’t matter much, therefore it is possible to choose something easy to sample from, as a uniform distribution. For simplicity, the distribution from which the noise is sampled is usually of a smaller dimension than the dimensionality of the output distribution. To train a neural network, its weights are updated to reduce the error or loss of its output.  In \ac{GAN}, however, the generator is not directly connected to the loss that is required to update its weights. The discriminator produces the generator loss as the generator feeds into the discriminator network. The generator loss penalizes the generator for generating a sample that the discriminator network classifies as fake. This extra piece of the implementation must be included in backpropagation. The backpropagation adjusts the weights in the appropriate direction by calculating the weight’s impact on the output — how the output would change if you updated the weights. But the impact of a generator weight depends on the discriminator weights it feeds into. So generator loss is backpropagated from the output of the discriminator to the generator. Means gradients flow back through the discriminator into the generator. At the same time, the discriminator will not change during generator training. Attempting to hit a moving target would make a complicated problem even difficult for the generator. The generator is trained with the following procedure: 1) Random noise input to the generator. 2) Generator produces output from sampled random noise. 3) The discriminator determines whether the generator output is “Real” or “Fake”. 4) Calculate loss from discriminator classification. 5) Backpropagate the generator loss through both the discriminator and generator to obtain gradients. 6) Use the gradients to update only the generator's weights.

\end{comment}

