%\noindent
\justifying
\setlength{\parskip}{1em}



In this chapter, the overview of this thesis is described by outlining the problem statement and the proposed solution in section \ref{Overview}. The results of the experiments conducted by the proposed image-to-image translation application to reduce the domain gap between synthetic data distribution and real data distribution are concluded in section \ref{Conclusion}. Finally, in section \ref{FutureWork} the limitations and future work are discussed.


\section{Overview}\label{Overview}

Since the last decades, many success stories about deep learning have been written. Also, it has evolved tremendously due to the introduction of neural networks, which learn complex patterns present in videos, images, and speeches. Nowadays, neural networks are widely used in autonomous vehicles, language translations, object detection, face recognition, speech recognition, and many other sophisticated applications. However, there are limitations to deep learning models. In traditional deep learning models, neural networks are trained and tested on similar data distribution or in the same domain to achieve the final objective by minimizing the error. In real-world scenarios, the data could arrive from different feature spaces, data distributions, and different domains. In such situations, neural networks don't generalize well to the data arrived from new data distribution or domain; for example, the model to detect pedestrian trained images of a pedestrian in summer might fail to detect pedestrians in winter. This problem of performance degradation causes because domain shift\cite{farahani2020brief}.

A large amount of training data is required to train neural networks to achieve low generalization error and high performance. However, training data are scarce and it is a very difficult job to collect and annotate the data. Hence, machine learning engineers required to create synthetic data, but neural networks trained using synthetic data will not generalize well on real data. So, over the year several domain adaption methodologies are developed by machine learning researchers to solve the problem of domain shift by closing the domain gap between two different domains\cite{farahani2020brief}. One of such domain adaptation methodologies is image-to-image translation, in which images from the source domain are transformed into the target domain by a function that learns the underlying characteristics extracted from the collection of images in both domains. For example, transforming the image of a zebra from the source domain into the image of a horse in the target domain, and vice versa.


\section{Conclusion}\label{Conclusion}

This thesis aims to solve the problem of data scarcity of real document images in the target domain using an image-to-image translation application. The proposed image-to-image translation application is developed using \ac{CycleGAN} to transform synthetic document images into realistic document images to close the domain gap between synthetic data distribution and real data distribution. The synthetic document images created using templates and handwritten crops are transformed into realistic document images to tackle the problem of data scarcity in the target domain further to improve the classifier of real document images. The quality of images generated using \ac{CycleGAN} is computed on the basis of how a classifier trained using images generated by the \ac{CycleGAN} generalizes to the testing dataset of annotated real document images. 


In this thesis, \ac{CycleGAN} is trained using form document images. The form document images consist of minute artifacts like check boxes, small fields, and different handwritings, which increases the complexity in the learning of neural networks. Most of the synthetic document images used for generating realistic document images are of type ``Bein", and they are very similar to each other. Small artifact transformation failure has caused the wrong classification because learning such distinct minor features present in training datasets by \ac{CycleGAN} is very challenging. The images of the type ``Arm'' and ``Hand'' are very distinct from the image type ``'Bein''. Hence, they are classified significantly well \ref{fig:CMCycleganGeneratedDocumentImagesClassifier}. Results conclude quantitatively the images generated using \ac{CycleGAN} did not match well to the real data distribution. Further, experiments conducted with dataset of synthetic document images, faxified document images to understand domain gap between these distributions and real data distribution. The quantitative results show the faxified data distribution has matched real data distribution significantly well compared to synthetic data distribution and \ac{CycleGAN} generated data distribution. 

Qualitatively the images generated using \ac{CycleGAN} are promising for further research (figure \ref{QualitativeResults}). Though qualitative results are promising, some typical failure cases have been identified, and it requires further attention in the future to improve the quality of \ac{CycleGAN} generated images. Failure cases like the transformation of handwriting crops from synthetic document images to realistic document images are failed (figure \ref{fig:failure1}), and the generated realistic document images have unrealistic noise, dark borders, and unrealistic artifacts (figures \ref{fig:failure2}, \ref{fig:failure3}, and \ref{fig:failure4})). In the next section \ref{FutureWork}, a discussion about improving the proposed image-to-image translation application is discussed, along with thesis limitations.

\section{Future Work}\label{FutureWork}

The proposed image-to-image translation application is implemented only using \acp{CycleGAN}. Comparison between other methodologies and chosen methodology \ac{CycleGAN} to transform synthetic document images into realistic document images is left for future research. For example \ac{CUT}\cite{park2020contrastive}, \ac{FastCUT}\cite{park2020contrastive}, \ac{ACL-GAN}\cite{zhao2021unpaired}, \ac{VAE}\cite{Kingma_2019}, and \ac{DCGAN}\cite{radford2016unsupervised} are recommended for future research. \acp{GAN} are a great success in generating realistic images, but the training process is not easy, the training is slow and unstable. \acp{GAN} are hard to train. It has problems like mode collapse, vanishing gradients, lack of proper evaluation metric, and hard to converge. The most important problem with \acp{GAN} is there no proper evaluation metric, without a good evaluation metric, it is like working in darkness. \acp{GAN} have complex object functions observing training progress is difficult, there is no signal to where to stop the training, also, there no single common and good performance indicator to evaluate numerous types of \acp{GAN}. In future, finding a proper performance indicator for \acp{GAN} can a part of research. 

In this thesis, \ac{CycleGAN}'s generators and discriminators are optimized using least-square loss function\cite{mao2017squares} to avoid mode collapse and vanishing gradient problems. The quality of generated images possibly would have been better if generators and discriminators of \ac{CycleGAN} would have optimized using the Wasserstein metric. Wasserstein distance metric is popularly used in \acp{WGAN}. \acp{WGAN} improve \ac{GAN}'s training by adopting a smooth Wasserstein distance metric for measuring the distance between two probability distributions\cite{arjovsky2017wasserstein}. Shrivastava et al.\cite{shrivastava2017learning} proposed a strategy for stable training. In which the discriminators are updated using a history of previously generated images instead of the ones produced recently by the generators. An image buffer of maintained to store 50 previously generated images. In the future, this strategy can be used to improve stability during the training and reduce model oscillations to produce better results\cite{shrivastava2017learning}. Qualitative results show the handwritten crops from synthetic document images were not reconstructed or transformed in the generated images (figure \ref{fig:failure1}). In the future, this thesis work can be extended to solve this problem, so the generated images are used to improve the handwriting recognition models. Training \ac{CycleGAN} sequentially is consumed numerous hours. Hence in the future, distributed training across multiple GPUs would be preferred while training the \acp{CycleGAN}.

Data analysis and data cleaning are the essential steps taken before training any neural network. The dataset used for the training the \ac{CycleGAN} consists of synthetic document images dataset and real document images dataset. The dataset of synthetic document images is equally distributed. Every selected class has the same number of samples. The dataset of real document images had random real images from different classes, which are unknown and disorganized. It is just a collection large number of real document images. In the future, to obtain better results the real document images dataset can be organized similarly to the synthetic document images dataset by performing data analysis and data cleaning at the initial stages of the research.


%This means the source domain is represented by synthetic document images and the target domain is represented by real document images. 



























%Wasserstein metric provides a smooth measure, which is super helpful for a stable learning process using gradient descents.
%Sadly, Wasserstein GAN is not perfect. Even the authors of the original WGAN paper mentioned that “Weight clipping is a clearly terrible way to enforce a Lipschitz constraint” (Oops!). WGAN still suffers from unstable training, slow convergence after weight clipping (when clipping window is too large), and vanishing gradients (when clipping window is too small).
%Second, to reduce model oscillation [15], we follow Shrivastava et al.’s strategy [46] and update the discriminators using a history of generated images rather than the ones produced by the latest generators. We keep an image buffer that stores the 50 previously created images.
%Wasserstein metric provides a smooth measure, which is super helpful for a stable learning process using gradient descents.
%The most important problem with \acp{GAN} is there no proper evaluation metric, without a good evaluation metric, it is like working in darkness. \acp{GAN} have complex object functions observing training progress is difficult, there is no signal to where to stop the training, also, there no single common and good performance indicator to evaluate numerous types of \acp{GAN}.
%Lack of a proper evaluation metric Generative adversarial networks are not born with a good objection function that can inform us the training progress. Without a good evaluation metric, it is like working in the dark. No good sign to tell when to stop; No good indicator to compare the performance of multiple models.