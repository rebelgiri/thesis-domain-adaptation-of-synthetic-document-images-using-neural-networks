%\noindent
\justifying
\setlength{\parskip}{1em}



In this chapter, the overview of this thesis is described by outlining the problem statement and the proposed solution. In section \ref{Overview} the overview of this thesis is briefly discussed. The results of the experiments conducted by the proposed image-to-image translation application to reduce the domain gap between synthetic data distribution and real data distribution are concluded in section \ref{Conclusion}. Finally, in section \ref{FutureWork} the limitations and future work are discussed.


\section{Overview}\label{Overview}

Since the last decades, many success stories have been written because of deep learning. In the field of computer vision, deep learning is the backbone of numerous sophisticated \ac{AI} applications. Also, it has grown remarkably due to the introduction of neural networks, which are capable of learning complex patterns present in videos, images and speeches. Nowadays, neural networks are widely used in autonomous vehicles, language translations, object detection, face recognition, speech recognition and many other sophisticated applications. However, deep learning models have some limitations, like training data scarcity and domain gap between training and real-world data distribution. In traditional deep learning models, neural networks are trained and tested on similar data distribution or in the same domain, to achieve the final objective by minimizing the error. In real-world scenarios, the data could arrive from different feature spaces, data distributions and different domains. In such situations, neural networks don't generalize well to the data arrived from new data distribution or domain, for example, the model to detect pedestrian trained images of a pedestrian in summer might fail to detect pedestrians in winter. This problem of performance degradation causes because of domain gap between two different data distributions \cite{farahani2020brief}. The domain gap is observed when a model is trained on one specific data distribution, but after deployment, it encounters another new and unseen data distribution, which leads to performance degradation of the model.

A large amount of training data is required to train neural networks to achieve low generalization error and high performance. However, as mentioned earlier, training data is scarce and it is a very difficult job to collect and annotate the data. Hence, inevitably, machine learning engineers are required to create synthetic data, but neural networks trained using synthetic data will not generalize well on real data. So, over the year several domain adaption methodologies are developed by machine learning researchers to reduce the domain gap between two different domains \cite{farahani2020brief}. One of such domain adaptation methodologies is image-to-image translation, in which images from the source domain are transformed and mapped into the target domain by a function that learns the underlying characteristics extracted from the collection of images in both domains. For example, transforming the image of a zebra from the source domain into the image of a horse in the target domain and vice versa. \ac{CycleGAN} is one of the popular methods to perform image-to-image translation. The prior image-to-image translation method like \ac{cGAN} requires paired training dataset from learning to transform and map images from one domain to another domain, but the \ac{CycleGAN} learns the underlying characteristics of both domains and performs the unpaired, unsupervised mage-to-image translation.


\section{Conclusion}\label{Conclusion}

This thesis aims to solve the problem of data scarcity of real document images in the target domain using an image-to-image translation application. The proposed image-to-image translation application is developed using \ac{CycleGAN} to transform synthetic document images into realistic document images to reduce the domain gap between synthetic data distribution and real data distribution. The \ac{CycleGAN} is trained using two datasets of document images, the source domain has synthetic document images and the target domain has real document images. The objective of this training would be to learn to translate an image from the source domain to the target domain and vice versa. The synthetic document images created using templates and handwritten crops. They are transformed into realistic document images to tackle the problem of data scarcity of real document images in the target domain. Once sufficient amount of images are generated in the target domain, tasks like real document images classification can be improved. The quality of images generated using \ac{CycleGAN} is computed based on how a classifier trained on images generated by the \ac{CycleGAN} generalizes to the testing dataset of annotated real document images. This way it can seen how close is the \ac{CycleGAN} generated data distribution to the real data distribution.

In this thesis, \ac{CycleGAN} is trained using document images of type form . The form document images consist of minute artifacts like check boxes, small fields and different handwritings, which increases the complexity in the learning of neural networks. Also, most of the synthetic document images used for generating realistic document images are of type ``Bein" and they are very similar to each other. Small artifact transformation failure has caused the wrong classification because learning such distinct minor features present in training datasets by \ac{CycleGAN} is very challenging. The images of the type ``Arm'' and ``Hand'' are very distinct from the image type ``Bein'', hence, they are classified significantly well \ref{fig:CMCycleganGeneratedDocumentImagesClassifier}. Experiments were conducted by training classifiers with dataset of synthetic document images, faxified document images and \ac{CycleGAN} generated document images respectively. These classifiers are evaluated using annotated real document images (testing dataset), to understand domain gap between these distributions and real data distribution. The experiment of training a classifier with \ac{CycleGAN} generated document images and evaluated by using annotated real document images, determines the quality of generated images, also gives an impression of how closely the generated data distribution matches to the real data distribution. The quantitative results show the faxified data distribution has matched real data distribution significantly well compared to synthetic data distribution and \ac{CycleGAN} generated data distribution and concluding results describe quantitatively the images generated using \ac{CycleGAN} did not match well to the real data distribution, and it must be improved in future work.

Qualitatively the images generated using \ac{CycleGAN} are promising for further research (figure \ref{QualitativeResults}). Though qualitative results are promising, some typical failure cases have been identified and it requires further attention in the future to improve the quality of \ac{CycleGAN} generated images. Failure cases like the transformation of handwriting crops from synthetic document images to realistic document images is failed (figure \ref{fig:failure1}) and the generated realistic document images have unrealistic noise, dark borders and unrealistic artifacts (figures \ref{fig:failure2}, \ref{fig:failure3} and \ref{fig:failure4})). In the next section \ref{FutureWork}, a discussion about improving the proposed image-to-image translation application is discussed, along with thesis limitations.

\section{Future Work}\label{FutureWork}

The proposed image-to-image translation application is implemented only using \ac{CycleGAN}. Comparison between other methodologies and chosen methodology \ac{CycleGAN} to transform synthetic document images into realistic document images is left for future research. For example \ac{CUT} \cite{park2020contrastive}, \ac{FastCUT} \cite{park2020contrastive}, \ac{ACL-GAN} \cite{zhao2021unpaired}, \ac{VAE} \cite{Kingma_2019} and \ac{DCGAN} \cite{radford2016unsupervised} are recommended for future research. \acp{GAN} are a great success in generating realistic images, but the training process is not easy, the training is slow and unstable. \acp{GAN} are hard to train. It has problems like mode collapse, vanishing gradients, lack of proper evaluation metric and hard to converge. The most important problem with \acp{GAN} is there no proper evaluation metric, without a good evaluation metric, it is like working in darkness. \acp{GAN} have complex objective functions, observing training progress is difficult, there is no signal to where to stop the training. Also, there no single common and good performance indicator to evaluate numerous types of \acp{GAN}. In future, finding a proper performance indicator for \acp{GAN} can a part of research. 

In this thesis, \ac{CycleGAN}'s generators and discriminators are optimized using least-square loss function \cite{mao2017squares} to avoid mode collapse and vanishing gradient problems. The quality of generated images possibly would have been better if generators and discriminators of \ac{CycleGAN} would have optimized using the Wasserstein metric \cite{arjovsky2017wasserstein}. Wasserstein distance metric is popularly used in \acp{WGAN}. \acp{WGAN} improve \ac{GAN}'s training by using a smooth Wasserstein distance metric to minimize the distance between two probability distributions \cite{arjovsky2017wasserstein}. Furthermore, Shrivastava et al.\ \cite{shrivastava2017learning} proposed a strategy for stable training, in which the discriminators are updated using a history of previously generated images instead of the ones produced recently by the generators. An image buffer of maintained to store 50 previously generated images. In the future, this strategy can be used to improve stability during the training and reduce model oscillations to produce better results \cite{shrivastava2017learning}. Qualitative results show the handwritten crops from synthetic document images did not reconstructed and transformed in the generated images (figure \ref{fig:failure1}). In the future, this research can be extended to solve this problem, so the generated images are used to improve the handwriting recognition models. Training \ac{CycleGAN} sequentially is consumed numerous hours. Hence in the future, distributed training across multiple GPUs would be preferred while training the \acp{CycleGAN}.

Data analysis and data cleaning are the essential steps taken before training any neural network. The two datasets are used for the training the \ac{CycleGAN}, which means the source domain is represented by the dataset of synthetic document images and the target domain is represented by the dataset of real document images. The dataset of synthetic document images is equally distributed. Every selected class has the same number of samples. The dataset of real document images had random real images from different classes, which are unknown and disorganized. It is just a collection large number of real document images. In the future, to obtain better results the real document images dataset can be organized similarly to the synthetic document images dataset by performing data analysis and data cleaning at the initial stages of the research.




























%Wasserstein metric provides a smooth measure, which is super helpful for a stable learning process using gradient descents.
%Sadly, Wasserstein GAN is not perfect. Even the authors of the original WGAN paper mentioned that “Weight clipping is a clearly terrible way to enforce a Lipschitz constraint” (Oops!). WGAN still suffers from unstable training, slow convergence after weight clipping (when clipping window is too large) and vanishing gradients (when clipping window is too small).
%Second, to reduce model oscillation [15], we follow Shrivastava et al.\’s strategy [46] and update the discriminators using a history of generated images rather than the ones produced by the latest generators. We keep an image buffer that stores the 50 previously created images.
%Wasserstein metric provides a smooth measure, which is super helpful for a stable learning process using gradient descents.
%The most important problem with \acp{GAN} is there no proper evaluation metric, without a good evaluation metric, it is like working in darkness. \acp{GAN} have complex object functions observing training progress is difficult, there is no signal to where to stop the training, also, there no single common and good performance indicator to evaluate numerous types of \acp{GAN}.
%Lack of a proper evaluation metric Generative adversarial networks are not born with a good objection function that can inform us the training progress. Without a good evaluation metric, it is like working in the dark. No good sign to tell when to stop; No good indicator to compare the performance of multiple models.